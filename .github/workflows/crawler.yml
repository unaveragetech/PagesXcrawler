name: Web Crawler

on:
  issues:
    types: [opened, edited]

jobs:
  crawl:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.title, 'crawl:')

    steps:
    - uses: actions/checkout@v2
      with:
        token: ${{ secrets.MY_PAT }}

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Parse issue title
      run: |
        issue_title="${{ github.event.issue.title }}"
        issue_number="${{ github.event.issue.number }}"

        # Function to add comment to the issue
        add_comment() {
          curl -X POST \
            -H "Authorization: token ${{ secrets.MY_PAT }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/issues/$issue_number/comments" \
            -d "{\"body\":\"$1\"}"
        }

        # Match the new format: crawl: URL DEPTH [OPTIONS]
        if [[ "$issue_title" =~ ^crawl:[[:space:]]*(https?://[^[:space:]]+)[[:space:]]+([0-9]+)(.*)$ ]]; then
            url="${BASH_REMATCH[1]}"
            depth="${BASH_REMATCH[2]}"
            options="${BASH_REMATCH[3]}"

            # Set default values
            max_pages=100
            timeout=10
            rotate_agent=10

            # Parse options if they exist
            if [ ! -z "$options" ]; then
                # Check for --max-pages
                if [[ "$options" =~ --max-pages[[:space:]]+([0-9]+) ]]; then
                    max_pages="${BASH_REMATCH[1]}"
                fi

                # Check for --timeout
                if [[ "$options" =~ --timeout[[:space:]]+([0-9]+) ]]; then
                    timeout="${BASH_REMATCH[1]}"
                fi

                # Check for --rotate-agent-after
                if [[ "$options" =~ --rotate-agent-after[[:space:]]+([0-9]+) ]]; then
                    rotate_agent="${BASH_REMATCH[1]}"
                fi
            fi

            # Export all variables
            {
                echo "URL=$url"
                echo "DEPTH=$depth"
                echo "MAX_PAGES=$max_pages"
                echo "TIMEOUT=$timeout"
                echo "ROTATE_AGENT=$rotate_agent"
                # Removed requests_per_second as it's handled automatically
                echo "ISSUE_TITLE=$issue_title"
                echo "ISSUE_NUMBER=$issue_number"
            } >> "$GITHUB_ENV"

            # Add configuration comment with proper escaping
            config_msg=$(cat <<EOF
ðŸ“‹ Configuration:
\`\`\`
URL: $url
Depth: $depth
Max Pages: $max_pages
Timeout: ${timeout}s
Rotate Agent: Every $rotate_agent requests
\`\`\`
EOF
)
            add_comment "$config_msg"
        else
            error_msg=$(cat <<'EOF'
âŒ Error: Invalid issue title format.

Please use this format:
\`\`\`
crawl: URL DEPTH [OPTIONS]
\`\`\`

Examples:
\`\`\`
crawl: https://example.com 3
crawl: https://example.com 2 --max-pages 50 --timeout 15 --rotate-agent-after 5
\`\`\`
EOF
)
            add_comment "$error_msg"
            exit 1
        fi

    - name: Run crawler
      run: |
        echo "Running crawler with configuration:"
        echo "URL: ${{ env.URL }}"
        echo "Depth: ${{ env.DEPTH }}"
        echo "Max Pages: ${{ env.MAX_PAGES }}"
        echo "Timeout: ${{ env.TIMEOUT }}"
        echo "Rotate Agent: ${{ env.ROTATE_AGENT }}"

        python crawler.py "${{ env.URL }}" "${{ env.DEPTH }}" \
          --max-pages "${{ env.MAX_PAGES }}" \
          --timeout "${{ env.TIMEOUT }}" \
          --rotate-agent-after "${{ env.ROTATE_AGENT }}"

    - name: Update visualization
      run: python scripts/update_html.py

    - name: Update issue status
      run: |
        echo "${{ env.ISSUE_TITLE }},${{ env.ISSUE_NUMBER }},completed" >> data/issues_status.csv

    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/* index.html
        git commit -m "Update data and visualization from issue #${{ env.ISSUE_NUMBER }}"
        git push

    - name: Close issue
      run: |
        # Add completion comment
        completion_msg="âœ… Crawl completed! View results:\n- [Dashboard](https://unaveragetech.github.io/PagesXcrawler/)\n- [CSV Data](https://github.com/${{ github.repository }}/blob/main/data/results.csv)\n- [JSON Data](https://github.com/${{ github.repository }}/blob/main/data/results.json)"

        curl -X POST \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ env.ISSUE_NUMBER }}/comments" \
          -d "{\"body\":\"$completion_msg\"}"

        curl -X PATCH \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ env.ISSUE_NUMBER }}" \
          -d '{"state":"closed"}'
