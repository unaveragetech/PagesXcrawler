name: Web Crawler

on:
  issues:
    types: [opened, edited]

jobs:
  crawl:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.title, ':depth(')
    
    steps:
    - uses: actions/checkout@v2
      with:
        token: ${{ secrets.MY_PAT }}

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Parse issue title and extract parameters
      run: |
        issue_title="${{ github.event.issue.title }}"
        issue_number="${{ github.event.issue.number }}"
        
        # Function to add comment to the issue
        add_comment() {
          curl -X POST \
            -H "Authorization: token ${{ secrets.MY_PAT }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/issues/$issue_number/comments" \
            -d "{\"body\":\"$1\"}"
        }

        # Parse URL and depth
        if [[ "$issue_title" =~ ^(https?://[^:]+):depth\(([0-9]+)\)(:params\(([^)]+)\))?$ ]]; then
          url="${BASH_REMATCH[1]}"
          depth="${BASH_REMATCH[2]}"
          params="${BASH_REMATCH[4]}"

          # Set defaults
          max_pages="100"
          timeout="10"
          rotate_agent="10"
          requests_per_second="2"

          # Parse parameters if they exist
          if [ ! -z "$params" ]; then
            IFS=',' read -ra PARAM_ARRAY <<< "$params"
            for param in "${PARAM_ARRAY[@]}"; do
              key="${param%%=*}"
              value="${param#*=}"
              case "$key" in
                "max-pages") max_pages="$value" ;;
                "timeout") timeout="$value" ;;
                "rotate-agent-after") rotate_agent="$value" ;;
                "requests-per-second") requests_per_second="$value" ;;
              esac
            done
          fi

          # Export variables
          echo "URL=$url" >> $GITHUB_ENV
          echo "DEPTH=$depth" >> $GITHUB_ENV
          echo "MAX_PAGES=$max_pages" >> $GITHUB_ENV
          echo "TIMEOUT=$timeout" >> $GITHUB_ENV
          echo "ROTATE_AGENT=$rotate_agent" >> $GITHUB_ENV
          echo "REQUESTS_PER_SECOND=$requests_per_second" >> $GITHUB_ENV
          
          # Add configuration comment
          config_msg="ðŸ“‹ Parsed configuration:\n\`\`\`\nURL: $url\nDepth: $depth\nMax Pages: $max_pages\nTimeout: ${timeout}s\nRotate Agent: Every $rotate_agent requests\nRequests/Second: $requests_per_second\n\`\`\`"
          add_comment "$config_msg"
        else
          error_msg="âŒ Error: Invalid issue title format.\n\nPlease use one of these formats:\n\`\`\`\nurl:depth(n)\nurl:depth(n):params(param1=value1,param2=value2)\n\`\`\`\n\nExamples:\n\`\`\`\nhttps://example.com:depth(3)\nhttps://example.com:depth(2):params(max-pages=50,timeout=15)\n\`\`\`"
          add_comment "$error_msg"
          exit 1
        fi

    - name: Run crawler
      run: |
        python crawler.py "${{ env.URL }}" "${{ env.DEPTH }}" \
          --max-pages "${{ env.MAX_PAGES }}" \
          --timeout "${{ env.TIMEOUT }}" \
          --rotate-agent-after "${{ env.ROTATE_AGENT }}" \
          --requests-per-second "${{ env.REQUESTS_PER_SECOND }}"

    - name: Update visualization
      run: python scripts/update_html.py

    - name: Update issue status
      run: |
        echo "${{ github.event.issue.title }},${{ github.event.issue.number }},completed" >> data/issues_status.csv

    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/* index.html
        git commit -m "Update data and visualization from issue #${{ github.event.issue.number }}"
        git push

    - name: Close issue
      run: |
        # Add completion comment
        completion_msg="âœ… Crawl completed! View results:\n- [Dashboard](https://unaveragetech.github.io/PagesXcrawler/)\n- [CSV Data](https://github.com/${{ github.repository }}/blob/main/data/results.csv)\n- [JSON Data](https://github.com/${{ github.repository }}/blob/main/data/results.json)"
        
        # Add completion comment
        curl -X POST \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments" \
          -d "{\"body\":\"$completion_msg\"}"
        
        # Close the issue
        curl -X PATCH \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.issue.number }}" \
          -d '{"state":"closed"}'
