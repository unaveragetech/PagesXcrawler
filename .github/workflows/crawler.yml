name: Web Crawler

on:
  issues:
    types: [opened, edited]

jobs:
  crawl:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.title, ':depth(')
    
    steps:
    - uses: actions/checkout@v2
      with:
        token: ${{ secrets.MY_PAT }}

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Parse issue title
      run: |
        issue_title="${{ github.event.issue.title }}"
        issue_number="${{ github.event.issue.number }}"
        
        # Function to add comment to the issue
        add_comment() {
          curl -X POST \
            -H "Authorization: token ${{ secrets.MY_PAT }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/issues/$issue_number/comments" \
            -d "{\"body\":\"$1\"}"
        }

        # Add initial status comment
        add_comment "🚀 Starting crawler with following configuration:\n\`\`\`\n$issue_title\n\`\`\`"

        # Parse basic format: url:depth(n)
        if [[ "$issue_title" =~ ^(https?://[^:]+):depth\(([0-9]+)\)$ ]]; then
          echo "URL=${BASH_REMATCH[1]}" >> $GITHUB_ENV
          echo "DEPTH=${BASH_REMATCH[2]}" >> $GITHUB_ENV
          echo "MAX_PAGES=100" >> $GITHUB_ENV
          echo "TIMEOUT=10" >> $GITHUB_ENV
          echo "ROTATE_AGENT=10" >> $GITHUB_ENV
        
        # Parse advanced format: url:depth(n):params(...)
        elif [[ "$issue_title" =~ ^(https?://[^:]+):depth\(([0-9]+)\):params\(([^)]+)\)$ ]]; then
          echo "URL=${BASH_REMATCH[1]}" >> $GITHUB_ENV
          echo "DEPTH=${BASH_REMATCH[2]}" >> $GITHUB_ENV
          
          # Parse parameters
          params="${BASH_REMATCH[3]}"
          IFS=',' read -ra PARAM_ARRAY <<< "$params"
          
          # Set defaults
          max_pages=100
          timeout=10
          rotate_agent=10
          
          # Process each parameter
          for param in "${PARAM_ARRAY[@]}"; do
            key="${param%%=*}"
            value="${param#*=}"
            case "$key" in
              "max-pages") max_pages="$value" ;;
              "timeout") timeout="$value" ;;
              "rotate-agent-after") rotate_agent="$value" ;;
            esac
          done
          
          echo "MAX_PAGES=$max_pages" >> $GITHUB_ENV
          echo "TIMEOUT=$timeout" >> $GITHUB_ENV
          echo "ROTATE_AGENT=$rotate_agent" >> $GITHUB_ENV
          
        else
          error_msg="❌ Error: Invalid issue title format.\n\nPlease use one of these formats:\n\`\`\`\nurl:depth(n)\nurl:depth(n):params(param1=value1,param2=value2)\n\`\`\`\n\nExamples:\n\`\`\`\nhttps://example.com:depth(3)\nhttps://example.com:depth(2):params(max-pages=50,timeout=15)\n\`\`\`"
          add_comment "$error_msg"
          exit 1
        fi

        # Add configuration confirmation
        config_msg="📋 Parsed configuration:\n\`\`\`\nURL: ${{ env.URL }}\nDepth: ${{ env.DEPTH }}\nMax Pages: ${{ env.MAX_PAGES }}\nTimeout: ${{ env.TIMEOUT }}s\nRotate Agent: Every ${{ env.ROTATE_AGENT }} requests\n\`\`\`"
        add_comment "$config_msg"

    - name: Run crawler
      run: |
        python crawler.py "${{ env.URL }}" "${{ env.DEPTH }}" \
          --max-pages "${{ env.MAX_PAGES }}" \
          --timeout "${{ env.TIMEOUT }}" \
          --rotate-agent-after "${{ env.ROTATE_AGENT }}"

    - name: Update visualization
      run: python scripts/update_html.py

    - name: Update issue status
      run: |
        echo "${{ github.event.issue.title }},${{ github.event.issue.number }},completed" >> data/issues_status.csv

    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/* index.html
        git commit -m "Update data and visualization from issue #${{ github.event.issue.number }}"
        git push

    - name: Close issue
      run: |
        # Add completion comment
        completion_msg="✅ Crawl completed! View results:\n- [Dashboard](https://unaveragetech.github.io/PagesXcrawler/)\n- [CSV Data](https://github.com/${{ github.repository }}/blob/main/data/results.csv)\n- [JSON Data](https://github.com/${{ github.repository }}/blob/main/data/results.json)"
        
        curl -X POST \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments" \
          -d "{\"body\":\"$completion_msg\"}"
        
        # Close the issue
        curl -X PATCH \
          -H "Authorization: token ${{ secrets.MY_PAT }}" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.issue.number }}" \
          -d '{"state":"closed"}'
